{"instance_id": "pydicom__pydicom-1256", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\nindex 1234567..89abcde 100644\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -210,6 +210,7 @@ class DatasetJSONDecoder:\n-                else:\n-                    value_key = unique_value_keys[0]\n-                    elem = DataElement.from_json(\n-                        self.dataset_class, key, vr,\n-                        val[value_key], value_key\n-                    )\n+                else:\n+                    value_key = unique_value_keys[0]\n+                    elem = DataElement.from_json(\n+                        self.dataset_class, key, vr,\n+                        val[value_key], value_key,\n+                        bulk_data_uri_handler=self.bulk_data_uri_handler\n+                    )\n"}
{"instance_id": "pydicom__pydicom-901", "model_name_or_path": "google/gemini-2.5-flash-lite", "model_patch": "--- a/pydicom/config.py\n+++ b/pydicom/config.py\n@@ -61,15 +61,9 @@\n     datetime_conversion = False\n \"\"\"Set datetime_conversion to convert DA, DT and TM\n data elements to datetime.date, datetime.datetime\n-and datetime.time respectively. Default: False\n-\"\"\"\n-\n-# Logging system and debug function to change logging level\n+and datetime.time respectively. Default: False\"\"\"\n+\n logger = logging.getLogger('pydicom')\n-handler = logging.StreamHandler()\n-formatter = logging.Formatter(\\\"%(message)s\\\")\n-handler.setFormatter(formatter)\n-logger.addHandler(handler)\n \n \n import pydicom.pixel_data_handlers.numpy_handler as np_handler  # noqa\n@@ -114,17 +110,14 @@\n     When debugging is on, file location and details about the\n     elements read at that location are logged to the 'pydicom'\n     logger using python's logging module.\n-\n     :param debug_on: True (default) to turn on debugging,\n     False to turn off.\n     \"\"\"\n-    global logger, debugging\n+    global logger\n     if debug_on:\n         logger.setLevel(logging.DEBUG)\n-        debugging = True\n     else:\n         logger.setLevel(logging.WARNING)\n-        debugging = False\n \n \n # force level=WARNING, in case logging default is set differently (issue 103)\n"}
{"instance_id": "pydicom__pydicom-1139", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\nindex 6f7d8a3..b9c3f2e 100644\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -800,5 +800,13 @@ class PersonName:\n-    def __bool__(self):\n-        if self.original_string is None:\n-            return (bool(self._components) and\n-                    (len(self._components) > 1 or bool(self._components[0])))\n-        return bool(self.original_string)\n+    def __bool__(self):\n+        if self.original_string is None:\n+            return (bool(self._components) and\n+                    (len(self._components) > 1 or bool(self._components[0])))\n+        return bool(self.original_string)\n+\n+    def __contains__(self, item):\n+        \"\"\"Allow 'in' operator to check if a substring is in the PersonName string.\"\"\"\n+        return item in str(self)\n+\n+    def __getattr__(self, name):\n+        \"\"\"Delegate attribute access to the string representation for str methods.\"\"\"\n+        return getattr(str(self), name)\n"}
{"instance_id": "pydicom__pydicom-901", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "@@ -45,6 +45,4 @@\n-# Logging system and debug function to change logging level\n-logger = logging.getLogger('pydicom')\n-handler = logging.StreamHandler()\n-formatter = logging.Formatter(\"%(message)s\")\n-handler.setFormatter(formatter)\n-logger.addHandler(handler)\n+logger = logging.getLogger('pydicom')\n+\n+\n+debugging = False\n@@ -121,20 +117,16 @@\n-def debug(debug_on=True):\n-    \"\"\"Turn debugging of DICOM file reading and writing on or off.\n-    When debugging is on, file location and details about the\n-    elements read at that location are logged to the 'pydicom'\n-    logger using python's logging module.\n-\n-    :param debug_on: True (default) to turn on debugging,\n-    False to turn off.\n-    \"\"\"\n-    global logger, debugging\n-    if debug_on:\n-        logger.setLevel(logging.DEBUG)\n-        debugging = True\n-    else:\n-        logger.setLevel(logging.WARNING)\n-        debugging = False\n-\n-\n-# force level=WARNING, in case logging default is set differently (issue 103)\n-debug(False)\n+def debug(debug_on=True):\n+    \"\"\"Turn debugging of DICOM file reading and writing on or off.\n+    When debugging is on, file location and details about the\n+    elements read at that location are logged to the 'pydicom'\n+    logger using python's logging module.\n+\n+    :param debug_on: True (default) to turn on debugging,\n+    False to turn off.\n+    \"\"\"\n+    global debugging\n+    debugging = bool(debug_on)\n+\n+    if debugging:\n+        logger.setLevel(logging.DEBUG)\n+    else:\n+        logger.setLevel(logging.WARNING)\n"}
{"instance_id": "pydicom__pydicom-1694", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/pydicom/dataset.py b/pydicom/dataset.py\nindex 1234567..89abcde 100644\n--- a/pydicom/dataset.py\n+++ b/pydicom/dataset.py\n@@ -2484,12 +2484,12 @@\n-        for key in self.keys():\n-            json_key = '{:08X}'.format(key)\n-            data_element = self[key]\n-            try:\n-                json_dataset[json_key] = data_element.to_json_dict(\n-                    bulk_data_element_handler=bulk_data_element_handler,\n-                    bulk_data_threshold=bulk_data_threshold\n-                )\n-            except Exception as exc:\n-                logger.error(f\\\"Error while processing tag {json_key}\\\")\n-                if not suppress_invalid_tags:\n-                    raise exc\n+        for key in self.keys():\n+            json_key = '{:08X}'.format(key)\n+            try:\n+                data_element = self[key]\n+                json_dataset[json_key] = data_element.to_json_dict(\n+                    bulk_data_element_handler=bulk_data_element_handler,\n+                    bulk_data_threshold=bulk_data_threshold\n+                )\n+            except Exception as exc:\n+                logger.error(f\\\"Error while processing tag {json_key}\\\")\n+                if not suppress_invalid_tags:\n+                    raise exc\n"}
{"instance_id": "pyvista__pyvista-4315", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/pyvista/core/grid.py b/pyvista/core/grid.py\nindex 1234567..89abcde 100644\n--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -120,14 +120,25 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n         elif len(args) == 3 or len(args) == 2:\n-            arg0_is_arr = isinstance(args[0], np.ndarray)\n-            arg1_is_arr = isinstance(args[1], np.ndarray)\n-            if len(args) == 3:\n-                arg2_is_arr = isinstance(args[2], np.ndarray)\n-            else:\n-                arg2_is_arr = False\n-\n-            if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n-                self._from_arrays(args[0], args[1], args[2], check_duplicates)\n-            elif all([arg0_is_arr, arg1_is_arr]):\n-                self._from_arrays(args[0], args[1], None, check_duplicates)\n-            else:\n-                raise TypeError(\\\"Arguments not understood by `RectilinearGrid`.\\\")\n+            # Convert sequences to np.ndarray\n+            def to_array(x):\n+                if isinstance(x, np.ndarray):\n+                    return x\n+                # Accept sequences (list, tuple) and convert to ndarray\n+                try:\n+                    return np.asarray(x)\n+                except Exception:\n+                    return x\n+\n+            arg0 = to_array(args[0])\n+            arg1 = to_array(args[1])\n+            arg2 = to_array(args[2]) if len(args) == 3 else None\n+\n+            arg0_is_arr = isinstance(arg0, np.ndarray)\n+            arg1_is_arr = isinstance(arg1, np.ndarray)\n+            arg2_is_arr = isinstance(arg2, np.ndarray) if arg2 is not None else False\n+\n+            if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n+                self._from_arrays(arg0, arg1, arg2, check_duplicates)\n+            elif all([arg0_is_arr, arg1_is_arr]):\n+                self._from_arrays(arg0, arg1, None, check_duplicates)\n+            else:\n+                raise TypeError(\\\"Arguments not understood by `RectilinearGrid`.\\\")\n"}
{"instance_id": "pylint-dev__astroid-1268", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/astroid/nodes/as_string.py b/astroid/nodes/as_string.py\nindex 1234567..89abcde 100644\n--- a/astroid/nodes/as_string.py\n+++ b/astroid/nodes/as_string.py\n@@ -100,1 +100,5 @@ class AsStringVisitor:\n-    # visit_<node> methods ###########################################\n+    # visit_<node> methods ###########################################\n+\n+    def visit_unknown(self, node):\n+        return \"Unknown\"\n+\n"}
{"instance_id": "pylint-dev__astroid-1866", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -937,1 +937,2 @@\n-    pos_values: list[str] = [i.value for i in inferred_positional]\n+    # Convert None values to string \"None\" to avoid TypeError in format\n+    pos_values: list[str] = [str(i.value) if i.value is None else i.value for i in inferred_positional]\n@@ -945,1 +953,4 @@\n-    keyword_values: dict[str, str] = {k: v.value for k, v in inferred_keyword.items()}\n+    # Convert None values to string \"None\" to avoid TypeError in format\n+    keyword_values: dict[str, str] = {\n+        k: str(v.value) if v.value is None else v.value for k, v in inferred_keyword.items()\n+    }\n@@ -957,5 +973,17 @@\n-    try:\n-        formatted_string = format_template.format(*pos_values, **keyword_values)\n-    except (IndexError, KeyError):\n-        # If there is an IndexError there are too few arguments to interpolate\n-        return iter([util.Uninferable])\n+    try:\n+        formatted_string = format_template.format(*pos_values, **keyword_values)\n+    except (IndexError, KeyError):\n+        # If there is an IndexError there are too few arguments to interpolate\n+        return iter([util.Uninferable])\n+    except TypeError as exc:\n+        # Catch TypeError from unsupported format string for NoneType\n+        if \"NoneType\" in str(exc):\n+            # Convert None values to string and try again\n+            pos_values = [str(v) for v in pos_values]\n+            keyword_values = {k: str(v) for k, v in keyword_values.items()}\n+            try:\n+                formatted_string = format_template.format(*pos_values, **keyword_values)\n+            except Exception:\n+                return iter([util.Uninferable])\n+        else:\n+            raise\n"}
{"instance_id": "pylint-dev__astroid-1196", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\nindex 1234567..89abcde 100644\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -2342,26 +2342,38 @@ class Dict(NodeNG, Instance):\n     def getitem(self, index, context=None):\n         \"\"\"Get an item from this node.\n \n         :param index: The node to use as a subscript index.\n         :type index: Const or Slice\n \n         :raises AstroidTypeError: When the given index cannot be used as a\n             subscript index, or if this node is not subscriptable.\n         :raises AstroidIndexError: If the given index does not exist in the\n             dictionary.\n         \"\"\"\n-        for key, value in self.items:\n-            # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n-            if isinstance(key, DictUnpack):\n-                try:\n-                    return value.getitem(index, context)\n-                except (AstroidTypeError, AstroidIndexError):\n-                    continue\n-            for inferredkey in key.infer(context):\n-                if inferredkey is util.Uninferable:\n-                    continue\n-                if isinstance(inferredkey, Const) and isinstance(index, Const):\n-                    if inferredkey.value == index.value:\n-                        return value\n-\n-        raise AstroidIndexError(index)\n+        for key, value in self.items:\n+            # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n+            if isinstance(key, DictUnpack):\n+                # If value is a reference, infer it first\n+                inferred_values = []\n+                try:\n+                    inferred_values = list(value.infer(context))\n+                except Exception:\n+                    # If inference fails, treat as uninferable\n+                    inferred_values = []\n+                for inferred_value in inferred_values:\n+                    if inferred_value is util.Uninferable:\n+                        continue\n+                    try:\n+                        return inferred_value.getitem(index, context)\n+                    except (AstroidTypeError, AstroidIndexError, AttributeError):\n+                        continue\n+                # If no inferred value worked, continue to next item\n+                continue\n+            for inferredkey in key.infer(context):\n+                if inferredkey is util.Uninferable:\n+                    continue\n+                if isinstance(inferredkey, Const) and isinstance(index, Const):\n+                    if inferredkey.value == index.value:\n+                        return value\n+\n+        raise AstroidIndexError(index)\n"}
{"instance_id": "pylint-dev__astroid-1978", "model_name_or_path": "google/gemini-2.5-flash-lite", "model_patch": "--- a/astroid/transforms.py\n+++ b/astroid/transforms.py\n@@ -97,19 +97,21 @@\n \n if HAS_NUMPY:\n     # Register numpy attributes\n-    for name in dir(np):\n-        if name.startswith(\"_\"):\n-            continue\n-        try:\n-            node = astroid.Attribute(name, lineno=1, col_offset=0)\n-            # Add the attribute to the module's locals\n-            # We need to be careful here, as some attributes might be\n-            # functions, classes, or other modules.\n-            # For now, we'll just add them as generic attributes.\n-            numpy_module.locals.append(node)\n-        except Exception:\n-            # Ignore attributes that cause errors during introspection\n-            pass\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"ignore\", FutureWarning)\n+        for name in dir(np):\n+            if name.startswith(\"_\"):\n+                continue\n+            try:\n+                node = astroid.Attribute(name, lineno=1, col_offset=0)\n+                # Add the attribute to the module's locals\n+                # We need to be careful here, as some attributes might be\n+                # functions, classes, or other modules.\n+                # For now, we'll just add them as generic attributes.\n+                numpy_module.locals.append(node)\n+            except Exception:\n+                # Ignore attributes that cause errors during introspection\n+                pass\n \n     # Add numpy.version to the module's locals\n     numpy_module.locals.append(astroid.Attribute(\"version\", lineno=1, col_offset=0))\n"}
{"instance_id": "pylint-dev__astroid-1978", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/astroid/raw_building.py b/astroid/raw_building.py\nindex 7a1e1b8..f9c7e2a 100644\n--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -463,11 +463,13 @@\n         if real_name != self._module.__name__:\n             # check if it sounds valid and then add an import node, else use a\n             # dummy node\n-            try:\n-                getattr(sys.modules[modname], name)\n-            except (KeyError, AttributeError):\n-                attach_dummy_node(node, name, member)\n-            else:\n-                attach_import_node(node, modname, name)\n+            try:\n+                with warnings.catch_warnings():\n+                    warnings.simplefilter(\"ignore\", FutureWarning)\n+                    getattr(sys.modules[modname], name)\n+            except (KeyError, AttributeError):\n+                attach_dummy_node(node, name, member)\n+            else:\n+                attach_import_node(node, modname, name)\n             return True\n         return False\n"}
{"instance_id": "pvlib__pvlib-python-1154", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "--- a/pvlib/irradiance.py\n+++ b/pvlib/irradiance.py\n@@ -882,1 +882,4 @@\n-    term3 = 1 + np.sqrt(HB / ghi) * (tools.sind(0.5 * surface_tilt) ** 3)\n+    # Avoid division by zero when ghi is zero\n+    term3 = 1 + np.where(ghi > 0,\n+                         np.sqrt(HB / ghi) * (tools.sind(0.5 * surface_tilt) ** 3),\n+                         0)\n"}
{"instance_id": "pvlib__pvlib-python-1854", "model_name_or_path": "google/gemini-2.5-flash-lite", "model_patch": "--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -250,7 +250,9 @@\n                 array_losses_parameters,\n             ),)\n         elif len(arrays) == 0:\n-            raise ValueError(\"PVSystem must have at least one Array. \"\n+            raise ValueError(\"PVSystem must have at least one Array. If you want to create a PVSystem instance with a single Array pass `arrays=None` and pass values directly to PVSystem attributes, e.g., `surface_tilt=30`\")\n+        elif isinstance(arrays, Array):\n+            self.arrays = (arrays,)\n                              \"If you want to create a PVSystem instance \"\n                              \"with a single Array pass `arrays=None` and pass \"\n                              \"values directly to PVSystem attributes, e.g., \"\n"}
{"instance_id": "pvlib__pvlib-python-1854", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\nindex 1234567..89abcde 100644\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -240,19 +240,23 @@ class PVSystem:\n-        if arrays is None:\n-            arrays = [Array(surface_tilt=surface_tilt,\n-                            surface_azimuth=surface_azimuth,\n-                            albedo=albedo,\n-                            surface_type=surface_type,\n-                            module=module,\n-                            module_type=module_type,\n-                            module_parameters=module_parameters,\n-                            temperature_model_parameters=temperature_model_parameters,\n-                            modules_per_string=modules_per_string,\n-                            strings_per_inverter=strings_per_inverter,\n-                            inverter=inverter,\n-                            inverter_parameters=inverter_parameters,\n-                            racking_model=racking_model,\n-                            losses_parameters=losses_parameters)]\n-        elif len(arrays) == 0:\n-            raise ValueError(\"PVSystem must have at least one Array. \"\n-                             \"If you want to create a PVSystem instance \"\n-                             \"without arrays, set arrays=None.\")\n+        if arrays is None:\n+            arrays = [Array(surface_tilt=surface_tilt,\n+                            surface_azimuth=surface_azimuth,\n+                            albedo=albedo,\n+                            surface_type=surface_type,\n+                            module=module,\n+                            module_type=module_type,\n+                            module_parameters=module_parameters,\n+                            temperature_model_parameters=temperature_model_parameters,\n+                            modules_per_string=modules_per_string,\n+                            strings_per_inverter=strings_per_inverter,\n+                            inverter=inverter,\n+                            inverter_parameters=inverter_parameters,\n+                            racking_model=racking_model,\n+                            losses_parameters=losses_parameters)]\n+        elif isinstance(arrays, Array):\n+            arrays = [arrays]\n+        elif len(arrays) == 0:\n+            raise ValueError(\"PVSystem must have at least one Array. \"\n+                             \"If you want to create a PVSystem instance \"\n+                             \"without arrays, set arrays=None.\")\n+\n+        self.arrays = arrays\n"}
{"instance_id": "pvlib__pvlib-python-1606", "model_name_or_path": "google/gemini-2.5-flash-lite", "model_patch": "--- a/pvlib/tools.py\n+++ b/pvlib/tools.py\n@@ -355,6 +355,14 @@\n     \\\"\\\"\\\"\\n\n \n     phim1 = (np.sqrt(5) - 1) / 2\n+\n+    # Handle cases where lower and upper bounds are equal or very close\n+    if np.allclose(lower, upper, atol=atol):\n+        # If bounds are equal, the optimal point is at that bound.\n+        # Evaluate func at 'lower' (or 'upper') and return.\n+        df = params.copy() # Create a copy to avoid modifying original params\n+        df['V1'] = lower\n+        return func(df, 'V1'), lower\n \n     df = params\n     df['VH'] = upper\n"}
{"instance_id": "pvlib__pvlib-python-1606", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/pvlib/tools.py b/pvlib/tools.py\nindex e3f7b2d..a4c9f9f 100644\n--- a/pvlib/tools.py\n+++ b/pvlib/tools.py\n@@ -338,37 +338,44 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-5):\n \n     phim1 = (np.sqrt(5) - 1) / 2\n \n-    df = params\n-    df['VH'] = upper\n-    df['VL'] = lower\n-\n-    converged = False\n-    iterations = 0\n-\n-    # handle all NaN case gracefully\n-    with warnings.catch_warnings():\n-        warnings.filterwarnings(action='ignore',\n-                                message='All-NaN slice encountered')\n-        iterlimit = 1 + np.nanmax(\n-            np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\n-\n-    while not converged and (iterations <= iterlimit):\n-\n-        phi = phim1 * (df['VH'] - df['VL'])\n-        df['V1'] = df['VL'] + phi\n-        df['V2'] = df['VH'] - phi\n-\n-        df['f1'] = func(df, 'V1')\n-        df['f2'] = func(df, 'V2')\n-        df['SW_Flag'] = df['f1'] > df['f2']\n-\n-        df['VL'] = df['V2']*df['SW_Flag'] + df['VL']*(~df['SW_Flag'])\n-        df['VH'] = df['V1']*~df['SW_Flag'] + df['VH']*(df['SW_Flag'])\n-\n-        err = abs(df['V2'] - df['V1'])\n-\n-        # works with single value because err is np.float64\n-        converged = (err[~np.isnan(err)] < atol).all()\n-        # err will be less than atol before iterations hit the limit\n-        # but just to be safe\n-        iterations += 1\n+    df = params.copy()\n+    df['VH'] = upper\n+    df['VL'] = lower\n+\n+    # If upper and lower bounds are equal, return the function value at that point\n+    if np.allclose(df['VH'], df['VL']):\n+        v = df['VH']\n+        f_val = func(df.assign(V1=v), 'V1')\n+        # Return a tuple with the power and voltage at max power point\n+        return f_val, v\n+\n+    converged = False\n+    iterations = 0\n+\n+    # handle all NaN case gracefully\n+    with warnings.catch_warnings():\n+        warnings.filterwarnings(action='ignore',\n+                                message='All-NaN slice encountered')\n+        iterlimit = 1 + np.nanmax(\n+            np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\n+\n+    while not converged and (iterations <= iterlimit):\n+\n+        phi = phim1 * (df['VH'] - df['VL'])\n+        df['V1'] = df['VL'] + phi\n+        df['V2'] = df['VH'] - phi\n+\n+        df['f1'] = func(df, 'V1')\n+        df['f2'] = func(df, 'V2')\n+        df['SW_Flag'] = df['f1'] > df['f2']\n+\n+        df['VL'] = df['V2']*df['SW_Flag'] + df['VL']*(~df['SW_Flag'])\n+        df['VH'] = df['V1']*~df['SW_Flag'] + df['VH']*(df['SW_Flag'])\n+\n+        err = abs(df['V2'] - df['V1'])\n+\n+        # works with single value because err is np.float64\n+        converged = (err[~np.isnan(err)] < atol).all()\n+        # err will be less than atol before iterations hit the limit\n+        # but just to be safe\n+        iterations += 1\n"}
{"instance_id": "pvlib__pvlib-python-1072", "model_name_or_path": "anthropic/claude-haiku-4-5-20251001", "model_patch": "--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -599,8 +599,12 @@ def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n \n     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n     # the value doesn't matter -- rather than recreate it here, just assume\n     # it's the same as the second timedelta:\n-    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\n+    # Convert timedeltas to hours. np.diff returns Timedelta objects for\n+    # tz-aware DatetimeIndex in pandas >= 1.0.0, so we need to handle both\n+    # cases (nanosecond ints and Timedelta objects).\n+    timedeltas = np.diff(poa_global.index)\n+    timedelta_hours = pd.to_timedelta(timedeltas).total_seconds() / 3600\n     timedelta_hours = np.append([timedelta_hours[0]], timedelta_hours)\n \n     tamb_array = temp_air + 273.15\n"}
{"instance_id": "pvlib__pvlib-python-1072", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -597,5 +597,10 @@\n-    # n.b. the way Fuentes calculates the first timedelta makes it seem like\n-    # the value doesn't matter -- rather than recreate it here, just assume\n-    # it's the same as the second timedelta:\n-    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\n-    timedelta_hours = np.append([timedelta_hours[0]], timedelta_hours)\n+    # n.b. the way Fuentes calculates the first timedelta makes it seem like\n+    # the value doesn't matter -- rather than recreate it here, just assume\n+    # it's the same as the second timedelta:\n+    if poa_global.index.tz is not None:\n+        index = poa_global.index.tz_convert(None)\n+    else:\n+        index = poa_global.index\n+\n+    timedelta_hours = np.diff(index.values.astype('datetime64[ns]').astype(np.int64)) / 1e9 / 60 / 60\n+    timedelta_hours = np.append([timedelta_hours[0]], timedelta_hours)\n"}
{"instance_id": "marshmallow-code__marshmallow-1343", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/src/marshmallow/schema.py b/src/marshmallow/schema.py\nindex abcdef12..12345678 100644\n--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -878,14 +878,16 @@ def _invoke_field_validators(self, unmarshal, data, many):\n-        else:\n-            try:\n-                value = data[field_obj.attribute or field_name]\n-            except KeyError:\n-                pass\n-            else:\n-                validated_value = unmarshal.call_and_store(\n-                    getter_func=validator,\n-                    data=value,\n-                    field_name=field_obj.load_from or field_name,\n-                    field_obj=field_obj\n-                )\n-                if validated_value is missing:\n-                    data.pop(field_name, None)\n+        else:\n+            if data is None:\n+                return\n+            try:\n+                value = data[field_obj.attribute or field_name]\n+            except KeyError:\n+                pass\n+            else:\n+                validated_value = unmarshal.call_and_store(\n+                    getter_func=validator,\n+                    data=value,\n+                    field_name=field_obj.load_from or field_name,\n+                    field_obj=field_obj\n+                )\n+                if validated_value is missing:\n+                    data.pop(field_name, None)\n"}
{"instance_id": "marshmallow-code__marshmallow-1359", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\nindex 0b18e7d..a1b2c3d 100644\n--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1110,7 +1110,11 @@ class DateTime(Field):\n-    def _bind_to_schema(self, field_name, schema):\n-        super()._bind_to_schema(field_name, schema)\n-        self.format = (\n-            self.format\n-            or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\n-            or self.DEFAULT_FORMAT\n-        )\n+    def _bind_to_schema(self, field_name, schema):\n+        super()._bind_to_schema(field_name, schema)\n+        # Use schema.opts if available, else fallback to root.opts\n+        opts = getattr(schema, \"opts\", None)\n+        if opts is None and hasattr(self, \"root\"):\n+            opts = getattr(self.root, \"opts\", None)\n+        self.format = (\n+            self.format\n+            or (getattr(opts, self.SCHEMA_OPTS_VAR_NAME) if opts else None)\n+            or self.DEFAULT_FORMAT\n+        )\n"}
{"instance_id": "sqlfluff__sqlfluff-1517", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/src/sqlfluff/core/linter/linter.py b/src/sqlfluff/core/linter/linter.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/src/sqlfluff/core/linter/linter.py\n+++ b/src/sqlfluff/core/linter/linter.py\n@@ -290,7 +290,29 @@ class Linter:\n-        if tokens:\n-            parsed, pvs = cls._parse_tokens(\n-                tokens, rendered.config, recurse=recurse, fname=rendered.fname\n-            )\n-            violations += pvs\n-        else:\n-            parsed = None\n+        if tokens:\n+            try:\n+                parsed, pvs = cls._parse_tokens(\n+                    tokens, rendered.config, recurse=recurse, fname=rendered.fname\n+                )\n+                violations += pvs\n+            except RuntimeError as err:\n+                # Catch the \"Dropped elements in sequence matching\" error and convert to unparsable violation\n+                err_msg = str(err)\n+                if \"Dropped elements in sequence matching\" in err_msg:\n+                    from sqlfluff.core.parser.segments.base import UnparsableSegment\n+                    # Create an UnparsableSegment with the raw string from the templated file if possible\n+                    raw_str = rendered.templated_file.raw if rendered.templated_file else rendered.raw_str\n+                    unparsable_seg = UnparsableSegment(raw=raw_str)\n+                    # Create a violation for unparsable section\n+                    from sqlfluff.core.errors import SQLParseError\n+                    violations.append(\n+                        SQLParseError(\n+                            message=\"Found unparsable section\",\n+                            line_no=1,\n+                            line_pos=1,\n+                            raw=raw_str,\n+                        )\n+                    )\n+                    parsed = unparsable_seg\n+                else:\n+                    raise\n+        else:\n+            parsed = None\n@@ -313,8 +349,8 @@ class Linter:\n-        return ParsedString(\n-            parsed,\n-            violations,\n-            time_dict,\n-            rendered.templated_file,\n-            rendered.config,\n-            rendered.fname,\n-        )\n+        return ParsedString(\n+            parsed,\n+            violations,\n+            time_dict,\n+            rendered.templated_file,\n+            rendered.config,\n+            rendered.fname,\n+        )\n"}
{"instance_id": "sqlfluff__sqlfluff-2419", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/src/sqlfluff/rules/L060.py b/src/sqlfluff/rules/L060.py\nindex 9b1a3e2..b3c4d7f 100644\n--- a/src/sqlfluff/rules/L060.py\n+++ b/src/sqlfluff/rules/L060.py\n@@ -37,17 +37,23 @@ class Rule_L060(BaseRule):\n-        # Only care if the function is ``IFNULL`` or ``NVL``.\n-        if context.segment.raw_upper not in {\\\"IFNULL\\\", \\\"NVL\\\"}:\n-            return None\n-\n-        # Create fix to replace ``IFNULL`` or ``NVL`` with ``COALESCE``.\n-        fix = LintFix.replace(\n-            context.segment,\n-            [\n-                CodeSegment(\n-                    raw=\\\"COALESCE\\\",\n-                    name=\\\"function_name_identifier\\\",\n-                    type=\\\"function_name_identifier\\\",\n-                )\n-            ],\n-        )\n-\n-        return LintResult(context.segment, [fix])\n+        # Only care if the function is ``IFNULL`` or ``NVL``.\n+        func_name = context.segment.raw_upper\n+        if func_name not in {\"IFNULL\", \"NVL\"}:\n+            return None\n+\n+        # Create fix to replace ``IFNULL`` or ``NVL`` with ``COALESCE``.\n+        fix = LintFix.replace(\n+            context.segment,\n+            [\n+                CodeSegment(\n+                    raw=\"COALESCE\",\n+                    name=\"function_name_identifier\",\n+                    type=\"function_name_identifier\",\n+                )\n+            ],\n+        )\n+\n+        # Return a message specific to the function found\n+        return LintResult(\n+            context.segment,\n+            [fix],\n+            description=f\"Use 'COALESCE' instead of '{func_name}'.\"\n+        )\n"}
{"instance_id": "sqlfluff__sqlfluff-1625", "model_name_or_path": "openai/gpt-4.1-mini", "model_patch": "diff --git a/src/sqlfluff/rules/L031.py b/src/sqlfluff/rules/L031.py\nindex 1234567..89abcde 100644\n--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -42,9 +42,19 @@ class Rule_L031(BaseRule):\n-            return (\n-                self._lint_aliases_in_join(\n-                    base_table,\n-                    from_expression_elements,\n-                    column_reference_segments,\n-                    segment,\n-                )\n-                or None\n-            )\n+            # Check if there is any join present in the from_clause_and_after segments\n+            join_present = any(\n+                clause.is_type(\"join_clause\") or clause.is_type(\"join_expression\")\n+                for clause in from_clause_and_after\n+            )\n+\n+            # If no join present, do not raise L031 violations\n+            if not join_present:\n+                return None\n+\n+            return (\n+                self._lint_aliases_in_join(\n+                    base_table,\n+                    from_expression_elements,\n+                    column_reference_segments,\n+                    segment,\n+                )\n+                or None\n+            )\n"}
